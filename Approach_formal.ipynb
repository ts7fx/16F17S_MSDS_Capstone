{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## This notebook contains modularized code for our two-step approach\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bytes</th>\n",
       "      <th>pkts</th>\n",
       "      <th>dur</th>\n",
       "      <th>rate</th>\n",
       "      <th>LOF_label</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1936</td>\n",
       "      <td>14</td>\n",
       "      <td>0.074</td>\n",
       "      <td>209297.63</td>\n",
       "      <td>1</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1500</td>\n",
       "      <td>14</td>\n",
       "      <td>0.065</td>\n",
       "      <td>184615.90</td>\n",
       "      <td>1</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3972</td>\n",
       "      <td>16</td>\n",
       "      <td>0.270</td>\n",
       "      <td>117688.89</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2294</td>\n",
       "      <td>14</td>\n",
       "      <td>0.169</td>\n",
       "      <td>108591.72</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13030</td>\n",
       "      <td>24</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1042400.99</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bytes  pkts    dur        rate  LOF_label  cluster_label\n",
       "0   1936    14  0.074   209297.63          1            299\n",
       "1   1500    14  0.065   184615.90          1            438\n",
       "2   3972    16  0.270   117688.89          1             73\n",
       "3   2294    14  0.169   108591.72          1             73\n",
       "4  13030    24  0.100  1042400.99          1             78"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Data Preprocessing ####\n",
    "# read netFlow data\n",
    "# data1 = pd.read_csv('~/Desktop/netFlow-02-11-2017.csv', sep = ',')\n",
    "# data_collab = data1[(((data1.srcAddr == '128.143.2.75') & (data1.srcPort == 443)) | ((data1.dstAddr =='128.143.2.75') & (data1.dstPort == 443)))]\n",
    "\n",
    "#### First step is to get anomaly scores from LOF/IForest, append to dataset.\n",
    "# input a dataframe, an anomaly detection method.\n",
    "# LOF, IForest, or nothing.\n",
    "def labeling(df, method):\n",
    "    # first step is to generate a list of anomaly scores using chosen method.\n",
    "    #if(method == \"IForest\"):\n",
    "#         train = test_sample1_pages[['bytes','pkts','dur','rate']]\n",
    "#         test = test_sample2_pages[['bytes','pkts','dur','rate']]\n",
    "#         clf = IsolationForest(max_samples=1000, contamination=0.05,random_state= 5, bootstrap=False)\n",
    "#         clf.fit(train)\n",
    "    if(method == \"LOF\"):\n",
    "        clf = LocalOutlierFactor(n_neighbors=20)\n",
    "        y_pred = clf.fit_predict(df)\n",
    "        df['LOF_label'] = y_pred\n",
    "    return(df)\n",
    "# take 50% sample data, then label it. \n",
    "# data_collab_labeled = labeling(data_collab.sample(frac = 0.5, replace = False), \"LOF\") \n",
    "\n",
    "\n",
    "#### Second step is to apply K-means clustering to the same dataset \n",
    "# kmeans = KMeans(n_clusters=553, random_state=0).fit(sample) # select K based on sqrt(n/2)\n",
    "# result = kmeans.labels_\n",
    "# data_collab_labeled['cluster_label'] = result\n",
    "# save the result..\n",
    "# data_collab_labeled.to_csv(\"~/Desktop/collab_clean_sample.csv\")\n",
    "\n",
    "# Read in sample data generated by extracint collab-related netFlow traffic.\n",
    "Collab_sample = pd.read_csv('~/Desktop/collab_clean_sample.csv')[[\"bytes\",'pkts','dur','rate','LOF_label','cluster_label']]\n",
    "Collab_sample.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10000130492511361"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Collab_sample[Collab_sample.LOF_label == -1]) / len(Collab_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04823166335541919"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Third step is to make use of the result of step 1 & 2, to reduce misclassified normal instances(reduce false alarm).\n",
    "# threshold is the maximum percentage of anomalies allowed in df\n",
    "\n",
    "def normal_profiling(df, threshold):\n",
    "    clusterID = df.cluster_label.values\n",
    "    df['normal_profile_labels'] = df['LOF_label']\n",
    "    labels = df[\"cluster_label\"].value_counts().index.tolist()\n",
    "    # when the proportion of anomalies is larger than a threshold\n",
    "    while (len(df[df.normal_profile_labels == -1]) / len(df) >= threshold):\n",
    "        # set anything that has label x, yet is classified by LOF to be an anomaly to be equal to 1. \n",
    "        x = labels.pop(0)\n",
    "        df.loc[((df['cluster_label'] == x) & (df['normal_profile_labels'] == -1)),'normal_profile_labels'] = 1\n",
    "    return(df)\n",
    "# case2: apply K-means repeatedly <-- not realistic because time-complexity\n",
    "Collab_norm = normal_profiling(Collab_sample, 0.05)\n",
    "len(Collab_norm[Collab_norm.normal_profile_labels == -1]) / len(Collab_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Forth step is to use majority vote to get final results.\n",
    "def maj_vote(df):\n",
    "    list = []\n",
    "    pool = set(df[df.normal_profile_labels == -1].cluster_label) # a set of IDs of all clusters that contain anomalies\n",
    "    # do majority vote, and return a list of anomalous clusters\n",
    "    for i in pool:\n",
    "        # for each of cluster i, calculate proportion of anomaly\n",
    "        proportion_anomaly = len(df[(df['cluster_label'] == i) & (df['normal_profile_labels'] == -1)]) / len(df[df.cluster_label == i])\n",
    "        if proportion_anomaly > 0.5:\n",
    "            list.extend([i])\n",
    "    return(list)\n",
    "anomaly_clusters = maj_vote(Collab_norm)\n",
    "len(anomaly_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# different sized culster for different algos for different datasets.\n",
    "\n",
    "## step1 data subsetting\n",
    "# 3 domains: collab, ECE, Shanti pages\n",
    "\n",
    "## port 443 \n",
    "\n",
    "\n",
    "## step2 \n",
    "# 3 combination of algos\n",
    "\n",
    "## step3\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
